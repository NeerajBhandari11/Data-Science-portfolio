{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Introduction\n",
    "   This project is to classify the twitter data provided for each user and to predict the Gender of the user ID provided in the test dataset.\n",
    "   To perform this task following steps are followed:\n",
    "   \n",
    "   * After loading Test and Train dataset into program the Userid is extracted from both into a list.\n",
    "   * Twitter data for each userid is fecthed from the xml file provided for each user.\n",
    "   * Text processing and the feature extraction process is done for tweets once after we extract data for all user from the unstructured data file and convert the extracted data into suitable format.\n",
    "   * After preprocessing, we split user data into train and test based on the user ID provided in Train and Test dataset respectively.\n",
    "   * Using the preprocessed data and extracted feature the classifier model is built to predict the gender of the user  data is fed into classifier to predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emoji\n",
    "import pandas as pd\n",
    "import xml.dom.minidom as x\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "import os\n",
    "# from emoji import UNICODE_EMOJI\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "import itertools\n",
    "import collections\n",
    "from nltk import FreqDist\n",
    "\n",
    "from sklearn import svm, tree\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(filename):  #function to load tweets for each user from xml file.\n",
    "    xml_data = x.parse(filename)  # parsing the xml file of the user\n",
    "    document_data = xml_data.getElementsByTagName('document') #extracting only document tag to get tweets\n",
    "    user_data = []\n",
    "#     print(document_data)\n",
    "    for data in document_data: #looping through all the document tag available(100 documents for each user)\n",
    "        temp_data = data.firstChild.data.lower() #getting data from the taqg\n",
    "#         print(temp_data)\n",
    "        user_data.append(temp_data) #appending tag into list\n",
    "    return user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "def get_tokenize_tweet(tweet):    #function to tokenise the tweet by keeping only the words with alphabets\n",
    "    token_tweet = []\n",
    "    token_no_stopwords = []\n",
    "#     tweet = tweet.lower()\n",
    "    tweet = re.sub(r'@(\\w+)+',' ',tweet)  # removing mentions from tweet\n",
    "    tweet = re.sub(r\"#(\\w+)\",' ',tweet) #removing mentions from tweet\n",
    "    tweet = re.sub('[\\'_]',' ',tweet)\n",
    "    tweet = re.sub(r\"http[s]?://(?:\\w+|\\d+|[$-_@.&+]|[!*\\(\\),]|(?:%[\\d\\w][\\d\\w]))+\",' ',tweet) # removing url from tweet\n",
    "    tokenizer = RegexpTokenizer(\"[A-Za-z]\\w+(?:[-'?]\\w+)?\")\n",
    "    temp_tweet = list(tokenizer.tokenize(tweet))\n",
    "    for word in temp_tweet:\n",
    "        word = word.lower()\n",
    "        if len(word) > 1:\n",
    "            token_tweet.append(word)\n",
    "            if word not in stopwords_list:\n",
    "                token_no_stopwords.append(word)                   \n",
    "    return token_tweet,token_no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "def remove_stopwords(tweet):\n",
    "    stop_removed_tweet = []\n",
    "    for word in tweet:\n",
    "        if word not in stopwords_list:\n",
    "            stop_removed_tweet.append(word)\n",
    "    return stop_removed_tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/neeraj/Neeraj/Data Science Projects/Twitter Sentiment Analysis/Assessment2_data'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os. getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user documents present in data folder: 3600\n"
     ]
    }
   ],
   "source": [
    "path, dirs, files = next(os.walk(\"/Users/neeraj/Neeraj/Data Science Projects/Twitter Sentiment Analysis/Assessment2_data/data/\")) #extracting all the filename from data folder\n",
    "filesname_list = []\n",
    "for file in files:\n",
    "    if file.endswith('.xml'):\n",
    "        filesname_list.append(file)\n",
    "file_count = len(set(filesname_list))\n",
    "print('Number of user documents present in data folder:',file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users combining Train and Test data: 3600\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/Users/neeraj/Neeraj/Data Science Projects/Twitter Sentiment Analysis/Assessment2_data/train_labels.csv\") #reading Train and test data\n",
    "test_data = pd.read_csv(\"/Users/neeraj/Neeraj/Data Science Projects/Twitter Sentiment Analysis/Assessment2_data/test.csv\")\n",
    "train_user_id_list = list(train_data['id'])\n",
    "test_user_id_list = list(test_data['id'])\n",
    "user_id_list = train_user_id_list  + test_user_id_list\n",
    "print('Number of users combining Train and Test data:',(len(set(user_id_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_lam = lambda file: re.sub('.xml','',file) # getting list of users by removing .xml from the filename list\n",
    "doc_userid_list = list(map(user_lam, files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading xml file of all the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.44 s, sys: 1.12 s, total: 5.56 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_data_list = []  \n",
    "user_id_list = []\n",
    "for file in filesname_list:\n",
    "    user_id = re.sub('.xml','',file) #extracting user ID from filenames\n",
    "    file_path = path + file  #creating path of file \n",
    "    temp_user_data = read_xml(file_path)   #reading xml file data\n",
    "    user_data_list.append(temp_user_data)\n",
    "    user_id_list.append(user_id)\n",
    "tweet_data_dict = dict(zip(user_id_list,user_data_list))  #creating dictionary using UserID as key and user tweets as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Tweets \n",
    "\n",
    "Steps in preprocessing:\n",
    "* Extracting all 100 tweets for each user.\n",
    "* for each tweets remove hashtags.\n",
    "* Remove URLS.\n",
    "* Remove mentions.\n",
    "* Remove spaces.\n",
    "* Extract words only with alpahbets by removing numbers and special characters.\n",
    "* Create list with all the words for each tweet [each tweet appened as new list].\n",
    "* Using above list, create bag of tweets(to create corpus) for each user [Combining all 100 tweets into list].\n",
    "* Create list with tweet word which are not stopwords.\n",
    "* Using stopword removed list, create bag of stopwords removed tweet words for each user.\n",
    "\n",
    "By using the four list createdd in above step and using userID, create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 883 ms, total: 15.8 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tweet_list = [] # tweet list for each user, which save list of tweets\n",
    "tweet_no_stopwords_list = [] # list in stopword removed tweets\n",
    "tweet_bag = [] #list is combine words from all 100 tweets for each user\n",
    "tweet_no_stopwords_bag = []\n",
    "user_id_list = []\n",
    "\n",
    "for user,data in tweet_data_dict.items(): #looping through each key and value in dictionary\n",
    "    temp_tweet = []  \n",
    "    temp_no_stopwords = []\n",
    "    tweet_corpus = []\n",
    "    tweet_no_stopwords_corpus = []\n",
    "    for tweet in data:   #looping through each tweet for a user\n",
    "        tweet_token,token_no_stopwords = get_tokenize_tweet(tweet) #extracting preprocessed tweet and stopword removed tweets\n",
    "        temp_tweet.append(tweet_token) #list of 100 preprocessed tweets separetly.\n",
    "        tweet_corpus += tweet_token #combining all 100 preprocessed tweets into 1 list.\n",
    "        \n",
    "    \n",
    "    #appending preprocessed data of a user into list\n",
    "    user_id_list.append(user)\n",
    "    tweet_list.append(temp_tweet)\n",
    "    tweet_bag.append(tweet_corpus)\n",
    "#creating dataframe using above list and user id   \n",
    "tweet_data_df = pd.DataFrame(list(zip(user_id_list,tweet_list,tweet_bag)),\n",
    "                             columns=['user_id','tweets','tweet_bag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tweet_bag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b91efc94c91ad3f882a612ae2682af17</td>\n",
       "      <td>[[news, flash, popcorn-flavored, tic-tacs, tas...</td>\n",
       "      <td>[news, flash, popcorn-flavored, tic-tacs, tast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ebb5b1633c16c5636f24bbfb70d26bb</td>\n",
       "      <td>[[another, superb, episode, while, can, wait, ...</td>\n",
       "      <td>[another, superb, episode, while, can, wait, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ff91e6d4b79fc64072ae273aa3fed77e</td>\n",
       "      <td>[[no, rod, city, has, continues, to, advocate,...</td>\n",
       "      <td>[no, rod, city, has, continues, to, advocate, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e199c5885131a2579429c07f3215cbc</td>\n",
       "      <td>[[separation, of, church, and, state], [all, t...</td>\n",
       "      <td>[separation, of, church, and, state, all, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cdc2d20d75f8187ee54caf56b2c77626</td>\n",
       "      <td>[[first, impressions, with, tina, fey], [warni...</td>\n",
       "      <td>[first, impressions, with, tina, fey, warning,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  \\\n",
       "0  b91efc94c91ad3f882a612ae2682af17   \n",
       "1  8ebb5b1633c16c5636f24bbfb70d26bb   \n",
       "2  ff91e6d4b79fc64072ae273aa3fed77e   \n",
       "3  7e199c5885131a2579429c07f3215cbc   \n",
       "4  cdc2d20d75f8187ee54caf56b2c77626   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  [[news, flash, popcorn-flavored, tic-tacs, tas...   \n",
       "1  [[another, superb, episode, while, can, wait, ...   \n",
       "2  [[no, rod, city, has, continues, to, advocate,...   \n",
       "3  [[separation, of, church, and, state], [all, t...   \n",
       "4  [[first, impressions, with, tina, fey], [warni...   \n",
       "\n",
       "                                           tweet_bag  \n",
       "0  [news, flash, popcorn-flavored, tic-tacs, tast...  \n",
       "1  [another, superb, episode, while, can, wait, t...  \n",
       "2  [no, rod, city, has, continues, to, advocate, ...  \n",
       "3  [separation, of, church, and, state, all, the,...  \n",
       "4  [first, impressions, with, tina, fey, warning,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Extraction\n",
    "Step 1: creating bigrams for all the words in tweet data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only top 200 bigram which is having frequncy morethan 20.\n",
    "# Bigrams for words which are not stopwords\n",
    "# Creating bigram with word lenght less than 3\n",
    "stp_word_list = stopwords.words()\n",
    "clean_tweets = tweet_data_df['tweet_bag']\n",
    "all_tweets = list(itertools.chain(*clean_tweets))\n",
    "bigram_list = []\n",
    "bigram_measure = nltk.collocations.BigramAssocMeasures() #creating bigrams\n",
    "bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(all_tweets)\n",
    "bigram_finder.apply_freq_filter(20) #filtering with frequency of 20\n",
    "bigram_finder.apply_word_filter(lambda w: len(w) < 3)# or w.lower() in ignored_words)\n",
    "bigram_finder.apply_ngram_filter(lambda w1, w2: w1 == w2)  #filetring bigram if both words are same\n",
    "bigram_finder.apply_ngram_filter(lambda w1, w2: w1  in stp_word_list or w2  in stp_word_list) #removing stopwords from bigram\n",
    "top_bigram_list = bigram_finder.nbest(bigram_measure.pmi, 200) # Selecting top 200 bigrams\n",
    "for value in top_bigram_list:\n",
    "    bigram_list.append(value[0]+\"_\"+value[1])  #extracting list of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of user_tweets after adding bigrams: 3600\n"
     ]
    }
   ],
   "source": [
    "bigram_tokenizer = MWETokenizer(mwes=top_bigram_list,separator= \"_\") #Adding bigram words to tokenizer with separator \"_\"\n",
    "user_tweets = tweet_data_df['tweet_bag']\n",
    "bigram_tweets_list = []\n",
    "for tweet in user_tweets: #looping through bag of user data\n",
    "    bigram_tweets_list.append(bigram_tokenizer.tokenize(tweet)) #creating bigrams using tokenizer    \n",
    "print('Lenght of user_tweets after adding bigrams:',len(bigram_tweets_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: creating trigrams for all the words in tweet data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only top 200 trigrams which is having frequncy morethan 20.\n",
    "# Trigrams for words which are not stopwords\n",
    "# Creating trigram with word lenght less than 3\n",
    "# Not creating the Trigram,If any two words in the trigrams are same.\n",
    "trigram_list = []\n",
    "all_tweets = list(itertools.chain(*bigram_tweets_list))\n",
    "trigram_measure = nltk.collocations.TrigramAssocMeasures() #creating trigrams\n",
    "trigram_finder = nltk.collocations.TrigramCollocationFinder.from_words(all_tweets)\n",
    "trigram_finder.apply_freq_filter(20) #filtering with frequency of 20\n",
    "trigram_finder.apply_word_filter(lambda words: len(words) < 3)# or w.lower() in ignored_words)\n",
    "trigram_finder.apply_ngram_filter(lambda word1,word2,word3: word1 == word2 or word2==word3 or word1==word3)  #filetring bigram if both words are same\n",
    "trigram_finder.apply_ngram_filter(lambda word1,word2,word3: word1 in stp_word_list or word2 in stp_word_list or word3 in stp_word_list) #removing stopwords from trigram\n",
    "top_trigram_list = trigram_finder.nbest(trigram_measure.pmi, 200) # Selecting top 200 bigrams\n",
    "for value in top_trigram_list: \n",
    "    trigram_list.append(value[0]+\"_\"+value[1]+\"_\"+value[2]) #Creating Trigrams list with'_' as seperator\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of user_tweets after adding bigrams: 3600\n"
     ]
    }
   ],
   "source": [
    "trigram_tokenizer = MWETokenizer(mwes=top_trigram_list,separator= \"_\") #Adding Trigram words to tokenizer with separator \"_\"\n",
    "trigram_tweets_list = []\n",
    "for tweet in bigram_tweets_list: #looping through tweets for which bigrams are created\n",
    "    trigram_tweets_list.append(trigram_tokenizer.tokenize(tweet))#creating trigrams using tokenizer \n",
    "print('Lenght of user_tweets after adding bigrams:',len(trigram_tweets_list))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remove stopwords before creating Ngrams, it will leads to __wrong set of Ngrams__.\n",
    "So removing it after __extracting Ngrams__ from the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_removed_tweets = []\n",
    "for user_tweets in trigram_tweets_list:\n",
    "    temp_tweet = remove_stopwords(user_tweets)\n",
    "    sw_removed_tweets.append(temp_tweet)\n",
    "len(sw_removed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tweet_bag</th>\n",
       "      <th>sw_removed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b91efc94c91ad3f882a612ae2682af17</td>\n",
       "      <td>[[news, flash, popcorn-flavored, tic-tacs, tas...</td>\n",
       "      <td>[news, flash, popcorn-flavored, tic-tacs, tast...</td>\n",
       "      <td>[news, flash, popcorn-flavored, tic-tacs, tast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ebb5b1633c16c5636f24bbfb70d26bb</td>\n",
       "      <td>[[another, superb, episode, while, can, wait, ...</td>\n",
       "      <td>[another, superb, episode, while, can, wait, t...</td>\n",
       "      <td>[another, superb, episode, wait, see, plays, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ff91e6d4b79fc64072ae273aa3fed77e</td>\n",
       "      <td>[[no, rod, city, has, continues, to, advocate,...</td>\n",
       "      <td>[no, rod, city, has, continues, to, advocate, ...</td>\n",
       "      <td>[rod, city, continues, advocate, bc, assessmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e199c5885131a2579429c07f3215cbc</td>\n",
       "      <td>[[separation, of, church, and, state], [all, t...</td>\n",
       "      <td>[separation, of, church, and, state, all, the,...</td>\n",
       "      <td>[separation, church, state, administration, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cdc2d20d75f8187ee54caf56b2c77626</td>\n",
       "      <td>[[first, impressions, with, tina, fey], [warni...</td>\n",
       "      <td>[first, impressions, with, tina, fey, warning,...</td>\n",
       "      <td>[first, impressions, tina, fey, warning, foota...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  \\\n",
       "0  b91efc94c91ad3f882a612ae2682af17   \n",
       "1  8ebb5b1633c16c5636f24bbfb70d26bb   \n",
       "2  ff91e6d4b79fc64072ae273aa3fed77e   \n",
       "3  7e199c5885131a2579429c07f3215cbc   \n",
       "4  cdc2d20d75f8187ee54caf56b2c77626   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  [[news, flash, popcorn-flavored, tic-tacs, tas...   \n",
       "1  [[another, superb, episode, while, can, wait, ...   \n",
       "2  [[no, rod, city, has, continues, to, advocate,...   \n",
       "3  [[separation, of, church, and, state], [all, t...   \n",
       "4  [[first, impressions, with, tina, fey], [warni...   \n",
       "\n",
       "                                           tweet_bag  \\\n",
       "0  [news, flash, popcorn-flavored, tic-tacs, tast...   \n",
       "1  [another, superb, episode, while, can, wait, t...   \n",
       "2  [no, rod, city, has, continues, to, advocate, ...   \n",
       "3  [separation, of, church, and, state, all, the,...   \n",
       "4  [first, impressions, with, tina, fey, warning,...   \n",
       "\n",
       "                                   sw_removed_tweets  \n",
       "0  [news, flash, popcorn-flavored, tic-tacs, tast...  \n",
       "1  [another, superb, episode, wait, see, plays, w...  \n",
       "2  [rod, city, continues, advocate, bc, assessmen...  \n",
       "3  [separation, church, state, administration, li...  \n",
       "4  [first, impressions, tina, fey, warning, foota...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data_df['sw_removed_tweets'] = sw_removed_tweets #creating new column with Ngrams extracted and stopwords removed tweets for each user\n",
    "tweet_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Using TFIDF of the tweets, the less frequent and more frequent word for removed from the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of words: 2379380\n"
     ]
    }
   ],
   "source": [
    "all_words = list(itertools.chain(*sw_removed_tweets))\n",
    "print('Total Number of words:',len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users 3600\n"
     ]
    }
   ],
   "source": [
    "#extracting unique words for each user tweets\n",
    "user_unique_word = [set(tweet) for tweet in tweet_data_df['sw_removed_tweets'] ]\n",
    "print('Number of users',len(user_unique_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_unique_words = list(itertools.chain(*user_unique_word))\n",
    "# len(all_tweet_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating frequency distribution(TFIDF for each word)\n",
    "word_freq_list = FreqDist(all_tweet_unique_words) \n",
    "word_freq_dict = dict(word_freq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_list = list(dict(word_freq_list).items()) \n",
    "word_freq_df = pd.DataFrame(word_freq_list,columns=['words','doc_count']) #creating DF using frequency distribution dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_df = word_freq_df.sort_values(by='doc_count') #sorting data to count of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of unique words:',len(word_freq_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_df[:10] #Top 10 least frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_df[-10:] #Top 10 most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing words appear in 95%[Number of user:3420]  and 5%[Number of user: 180] of usertweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_user = len(tweet_data_df)\n",
    "len(word_freq_df[(word_freq_df[\"doc_count\"]> int(total_user*0.95))] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are no words appearing in 3420 (95%) of users tweets, so making the maximum threshold as 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_df[(word_freq_df[\"doc_count\"]> int(total_user*0.85))] #words available in 85% for users tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_freq_df[(word_freq_df[\"doc_count\"]< int(total_user*0.01))]) #count of words avaiable only in 5% users tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is helpful. more words appears only in  180 (5%) users tweets, Removing of this words will help our model to perform well with less time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting frequent words from the dataframe based on th threshold dataframe\n",
    "threshold_word_list = list(word_freq_df[(word_freq_df[\"doc_count\"]> int(total_user*0.85))]['words'])\n",
    "threshold_word_list += list(word_freq_df[(word_freq_df[\"doc_count\"] < int(total_user*0.05))]['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of words comes in the provided document threshold:',len(threshold_word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the words which are in the given document threshold for all the users tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As the threshold words contains more word, it will take more time to comapre words in for loop using the list.\n",
    "* So to save the time, we are taking the intersection of the tweet words set and the set of threshold words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "freq_word_rm_list = []\n",
    "sw_removed_tweets_list = list(tweet_data_df['sw_removed_tweets']) # cleaned words list to remove the threshold words\n",
    "freq_rm_tweets_list = []\n",
    "for user_tweet in sw_removed_tweets_list: #looping through all the  tweets\n",
    "    #extracting only words from tweets, which are not in threshold words\n",
    "    # converting both lists into set for easy comparision using set intersection\n",
    "    words = list(set(user_tweet) - set(threshold_word_list)) \n",
    "    user_tweet = [word for word in user_tweet if word in words]\n",
    "    freq_rm_tweets_list.append(user_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(freq_rm_tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_df['freq_rm_tweets'] = freq_rm_tweets_list\n",
    "tweet_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection \n",
    "\n",
    "To select the classifier with best accuracy and performance, we are using 6 classifiers on the data.\n",
    "\n",
    "Classifiers are:\n",
    "* LogisticRegression\n",
    "* SVC\n",
    "* LinerSVC\n",
    "* DecisionTree classifer\n",
    "* RandomForest classifier\n",
    "* MLPClassifier\n",
    "\n",
    "All the model for build on the data extracted from the four different method of vectorisors:\n",
    "\n",
    "Feature vector extract method:\n",
    "1. TFIDF vectoriser with binary parameter as False\n",
    "2. TFIDF vectoriser with binary parameter as True\n",
    "3. Count vectoriser with binary parameter as True\n",
    "4. Count vectoriser with binary parameter as False\n",
    "\n",
    "All 6 classifiers are build on each feature extraction method. So we build 4(method)*6(classifier) = __24 models__ to select the best classifier and the vectorising method in the following setps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test dataset based in the User ID provided in train and test lable file\n",
    "test_labels = pd.read_csv('Assessment2_data/test_labels.csv')\n",
    "train_df= pd.merge(train_data, tweet_data_df, left_on='id',right_on='user_id')\n",
    "test_df = pd.merge(test_labels, tweet_data_df, left_on='id',right_on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit and get accuracy and F1_score for the model \n",
    "def get_accuracy_model(model,train_x, test_x, train_y, test_y):\n",
    "    model.fit(train_x,train_y) #fit model using train_x and train_y dataset\n",
    "    predict_y = model.predict(test_x) #opredicting y value \n",
    "    accuracy = accuracy_score(test_y,predict_y) # calculating accuracy\n",
    "    f1_score1 = f1_score(test_y,predict_y,average='macro')\n",
    "    return (accuracy,f1_score1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to create all 6 models which are using in this task and to get accuracy for each of them\n",
    "def create_all_model(train_x,train_y,test_x,test_y,node_classification):\n",
    "        \n",
    "    node_classification_list = []\n",
    "    model_name_list = ['LogisticRegression','SVC','LinearSVC','DecisionTree','RandomForest','MLPClassifier']\n",
    "    accuracy_score_list = []\n",
    "    f1_score_list = []\n",
    "    accu_result = []\n",
    "    #splitting data into train and test data\n",
    "    lr_model = LogisticRegression() #creating LogisticRegression model\n",
    "    # getting accuracy and F1_score for LogisticRegression\n",
    "    accu_result.append(get_accuracy_model(lr_model,train_x, test_x, train_y, test_y))\n",
    "    \n",
    "    svc_model = SVC() #creating SVC model\n",
    "    #getting accuracy and F1_score for SVC\n",
    "    accu_result.append(get_accuracy_model(svc_model,train_x, test_x, train_y, test_y))\n",
    "    \n",
    "    lsvc_model = LinearSVC() #creating LinearSVC model\n",
    "    #getting accuracy and F1_score for LinearSVC\n",
    "    accu_result.append(get_accuracy_model(lsvc_model,train_x, test_x, train_y, test_y))\n",
    "  \n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy') #creating Decision Tree model\n",
    "    #getting accuracy and F1_score for Decision Tree model    \n",
    "    accu_result.append(get_accuracy_model(dt_model,train_x, test_x, train_y, test_y))\n",
    "\n",
    "    rf_model = RandomForestClassifier()#creating RandomForest classifier\n",
    "    #getting accuracy and F1_score for RandomForest classifier\n",
    "    accu_result.append(get_accuracy_model(rf_model,train_x, test_x, train_y, test_y))\n",
    "    \n",
    "    ml_model = MLPClassifier(hidden_layer_sizes=(400,),alpha=0.9)\n",
    "    accu_result.append(get_accuracy_model(ml_model,train_x, test_x, train_y, test_y))\n",
    "    \n",
    "    \n",
    "    for accuracy in accu_result: #looping through accuracy of each classifier\n",
    "        node_classification_list.append(node_classification) #appending node_classification method name\n",
    "        accuracy_score_list.append(accuracy[0]) #accuracy into list\n",
    "        f1_score_list.append(accuracy[1]) #F1_score into list\n",
    "    #result dataframe for the classifier build using the particular node classifier\n",
    "    accu_df = pd.DataFrame(list(zip(node_classification_list,model_name_list,accuracy_score_list,f1_score_list)),\n",
    "                         columns = ['Feature_extraction type','Classifier','Accuracy','F1_score'])\n",
    "    return accu_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# converting the bag of words for each users tweet into str, to generate feature vectoe\n",
    "train_tweets = []\n",
    "test_tweets = []\n",
    "for tweet in train_df['freq_rm_tweets']:\n",
    "    strn = ' '.join(word for word in tweet)\n",
    "    train_tweets.append(strn)\n",
    "    \n",
    "for tweet in test_df['freq_rm_tweets']:\n",
    "    strn = ' '.join(word for word in tweet)\n",
    "    test_tweets.append(strn)\n",
    "    \n",
    "\n",
    "# extracting y labels from the train and test data   \n",
    "y_train = train_df['gender']\n",
    "y_test = test_df['gender']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Tdidf with binary as False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.1 s, sys: 2.82 s, total: 56.9 s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# tfidfconverter = TfidfVectorizer(binary=False)\n",
    "# x_train = tfidfconverter.fit_transform(train_tweets).toarray()\n",
    "# x_test = tfidfconverter.fit_transform(test_tweets).toarray()    \n",
    "# tdidf_false_df = create_all_model(x_train,y_train,x_test,y_test,'TFIDF with Binary: False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_extraction type</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.815953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.331551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.775943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.611901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.651175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.805589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_extraction type          Classifier  Accuracy  F1_score\n",
       "0  TFIDF with Binary: False  LogisticRegression     0.816  0.815953\n",
       "1  TFIDF with Binary: False                 SVC     0.496  0.331551\n",
       "2  TFIDF with Binary: False           LinearSVC     0.776  0.775943\n",
       "3  TFIDF with Binary: False        DecisionTree     0.612  0.611901\n",
       "4  TFIDF with Binary: False        RandomForest     0.654  0.651175\n",
       "5  TFIDF with Binary: False       MLPClassifier     0.806  0.805589"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tdidf_false_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method Logistic Regression is performing better with 0.816 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Tdidf with binary as True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 s, sys: 2.64 s, total: 53.8 s\n",
      "Wall time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# tfidfconverter = TfidfVectorizer(binary=True)\n",
    "# x_train = tfidfconverter.fit_transform(train_tweets).toarray()\n",
    "# x_test = tfidfconverter.fit_transform(test_tweets).toarray()\n",
    "# tdidf_true_df =create_all_model(x_train,y_train,x_test,y_test,'TFIDF with Binary: True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_extraction type</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.805825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.331551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.769925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.622642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.633886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.785278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_extraction type          Classifier  Accuracy  F1_score\n",
       "0  TFIDF with Binary: True  LogisticRegression     0.806  0.805825\n",
       "1  TFIDF with Binary: True                 SVC     0.496  0.331551\n",
       "2  TFIDF with Binary: True           LinearSVC     0.770  0.769925\n",
       "3  TFIDF with Binary: True        DecisionTree     0.624  0.622642\n",
       "4  TFIDF with Binary: True        RandomForest     0.638  0.633886\n",
       "5  TFIDF with Binary: True       MLPClassifier     0.786  0.785278"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tdidf_true_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method performance Logistic Regression is slightly decresed and best performing model is MLP classifier with  better with accuracy of 0.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3: count vectorizer with binary as True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.4 s, sys: 2.88 s, total: 52.3 s\n",
      "Wall time: 36.4 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# count_vect = CountVectorizer(binary=True)\n",
    "# x_train = count_vect.fit_transform(train_tweets).toarray()\n",
    "# x_test = count_vect.fit_transform(test_tweets).toarray()\n",
    "# cnt_vec_true_df = create_all_model(x_train,y_train,x_test,y_test,'Count_vec with Binary: True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_extraction type</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.719996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.791880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.681938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.657988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.653784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.751996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature_extraction type          Classifier  Accuracy  F1_score\n",
       "0  Count_vec with Binary: True  LogisticRegression     0.720  0.719996\n",
       "1  Count_vec with Binary: True                 SVC     0.792  0.791880\n",
       "2  Count_vec with Binary: True           LinearSVC     0.682  0.681938\n",
       "3  Count_vec with Binary: True        DecisionTree     0.658  0.657988\n",
       "4  Count_vec with Binary: True        RandomForest     0.656  0.653784\n",
       "5  Count_vec with Binary: True       MLPClassifier     0.752  0.751996"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cnt_vec_true_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbeliveable, the performance of SVC increased significantly in this method and it is best model with 0.79 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 4 : count vectorizer with binary as False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.7 s, sys: 2.91 s, total: 51.6 s\n",
      "Wall time: 36.7 s\n"
     ]
    }
   ],
   "source": [
    "# %%time \n",
    "# count_vect = CountVectorizer(binary=False)\n",
    "# x_train = count_vect.fit_transform(train_tweets).toarray()\n",
    "# x_test = count_vect.fit_transform(test_tweets).toarray()\n",
    "# cnt_vec_false_df = create_all_model(x_train,y_train,x_test,y_test,'Count_vec with Binary: False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_extraction type</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.745999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.807923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.639024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.695956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.783945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature_extraction type          Classifier  Accuracy  F1_score\n",
       "0  Count_vec with Binary: False  LogisticRegression     0.746  0.745999\n",
       "1  Count_vec with Binary: False                 SVC     0.808  0.807923\n",
       "2  Count_vec with Binary: False           LinearSVC     0.736  0.736000\n",
       "3  Count_vec with Binary: False        DecisionTree     0.640  0.639024\n",
       "4  Count_vec with Binary: False        RandomForest     0.698  0.695956\n",
       "5  Count_vec with Binary: False       MLPClassifier     0.784  0.783945"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cnt_vec_false_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the SVC model beats all other model with 0.80 accuracy, in this method.\n",
    "\n",
    "we can observe that the SVC classifier is performing better with countvectoriser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the best model and feature vector method based on the accuracy and F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = [tdidf_true_df,tdidf_false_df,cnt_vec_false_df,cnt_vec_true_df] #merging result of all methods into one \n",
    "# final_res_df = pd.concat(res,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models build for model and feature vector method selection: 24\n"
     ]
    }
   ],
   "source": [
    "# print('Number of models build for model and feature vector method selection:',len(final_res_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_extraction type</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.815953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.807923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.805825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.805589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.791880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.785278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.783945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.775943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.769925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.751996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.745999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.719996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.695956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.681938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.657988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Count_vec with Binary: True</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.653784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.651175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Count_vec with Binary: False</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.639024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.633886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.622642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.611901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TFIDF with Binary: True</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.331551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TFIDF with Binary: False</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.331551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature_extraction type          Classifier  Accuracy  F1_score\n",
       "6       TFIDF with Binary: False  LogisticRegression     0.816  0.815953\n",
       "13  Count_vec with Binary: False                 SVC     0.808  0.807923\n",
       "0        TFIDF with Binary: True  LogisticRegression     0.806  0.805825\n",
       "11      TFIDF with Binary: False       MLPClassifier     0.806  0.805589\n",
       "19   Count_vec with Binary: True                 SVC     0.792  0.791880\n",
       "5        TFIDF with Binary: True       MLPClassifier     0.786  0.785278\n",
       "17  Count_vec with Binary: False       MLPClassifier     0.784  0.783945\n",
       "8       TFIDF with Binary: False           LinearSVC     0.776  0.775943\n",
       "2        TFIDF with Binary: True           LinearSVC     0.770  0.769925\n",
       "23   Count_vec with Binary: True       MLPClassifier     0.752  0.751996\n",
       "12  Count_vec with Binary: False  LogisticRegression     0.746  0.745999\n",
       "14  Count_vec with Binary: False           LinearSVC     0.736  0.736000\n",
       "18   Count_vec with Binary: True  LogisticRegression     0.720  0.719996\n",
       "16  Count_vec with Binary: False        RandomForest     0.698  0.695956\n",
       "20   Count_vec with Binary: True           LinearSVC     0.682  0.681938\n",
       "21   Count_vec with Binary: True        DecisionTree     0.658  0.657988\n",
       "22   Count_vec with Binary: True        RandomForest     0.656  0.653784\n",
       "10      TFIDF with Binary: False        RandomForest     0.654  0.651175\n",
       "15  Count_vec with Binary: False        DecisionTree     0.640  0.639024\n",
       "4        TFIDF with Binary: True        RandomForest     0.638  0.633886\n",
       "3        TFIDF with Binary: True        DecisionTree     0.624  0.622642\n",
       "9       TFIDF with Binary: False        DecisionTree     0.612  0.611901\n",
       "1        TFIDF with Binary: True                 SVC     0.496  0.331551\n",
       "7       TFIDF with Binary: False                 SVC     0.496  0.331551"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_res_df.sort_values(['Accuracy','F1_score'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the above data, we can clearly say that the __Logistic Regression__ is giving better result with __TFIDF with binary Flase__ Vectorriser .\n",
    "* Accuracy of this model is 0.816"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning  model \n",
    "* Logistic Regression model to select the best hyperparamter for the model, to get best result.\n",
    "* This will be done using __Grid search cross validation method__ (GridseachCV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 98.3 ms, total: 1.37 s\n",
      "Wall time: 10.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    9.8s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#creting feature vector using selected best vectorising method(TDIDF with binary False)\n",
    "tfidfconverter = TfidfVectorizer(binary=False)\n",
    "x_train = tfidfconverter.fit_transform(train_tweets).toarray()\n",
    "x_test = tfidfconverter.fit_transform(test_tweets).toarray()\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('classifier' , LogisticRegression())])\n",
    "\n",
    "\n",
    "# Creating param grid with multiple values for the parameters\n",
    "param_grid = [\n",
    "    {\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "     'classifier__C' : list(range(2, 20, 2)),\n",
    "     'classifier__solver' : ['liblinear']},]\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(pipeline, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data on GridSearchCV model\n",
    "best_clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('classifier',\n",
       "   LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "             tol=0.0001, verbose=0, warm_start=False))],\n",
       " 'classifier': LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'classifier__C': 2,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__dual': False,\n",
       " 'classifier__fit_intercept': True,\n",
       " 'classifier__intercept_scaling': 1,\n",
       " 'classifier__max_iter': 100,\n",
       " 'classifier__multi_class': 'warn',\n",
       " 'classifier__n_jobs': None,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__random_state': None,\n",
       " 'classifier__solver': 'liblinear',\n",
       " 'classifier__tol': 0.0001,\n",
       " 'classifier__verbose': 0,\n",
       " 'classifier__warm_start': False}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.get_params() #displaying the best parameters to get better result/accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It tells best parameters that Logistic model are:\n",
    " * C is 2\n",
    " * penalty is 'l2' and so on.\n",
    " Now creating model with the above parameter value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
    "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
    "           n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
    "           tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Tuned model is : 0.822\n",
      "F1_score of the Tuned model is : 0.8219992879971519\n"
     ]
    }
   ],
   "source": [
    "# m.fit(x_train,y_train)\n",
    "model = model.fit(x_train,y_train)\n",
    "prediction = model.predict(x_test)\n",
    "accuracy,f1_score = get_accuracy_model(model,x_train,x_test,y_train,y_test)\n",
    "print('Accuracy of the Tuned model is :',accuracy)\n",
    "print('F1_score of the Tuned model is :',f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predticing gender for the user in test data using selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(x_train,y_train)\n",
    "prediction = model.predict(x_test)\n",
    "test_df['prediction'] = prediction #attaching prediction into test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tweet_bag</th>\n",
       "      <th>sw_removed_tweets</th>\n",
       "      <th>freq_rm_tweets</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>male</td>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>[[what, odds, he, stops, whining, and, goes, o...</td>\n",
       "      <td>[what, odds, he, stops, whining, and, goes, ou...</td>\n",
       "      <td>[odds, stops, whining, goes, gets, proper, job...</td>\n",
       "      <td>[goes, gets, proper, job, rest, us, would, ima...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>female</td>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>[[bingay, won, cool, handy, tonight], [], [we,...</td>\n",
       "      <td>[bingay, won, cool, handy, tonight, we, made, ...</td>\n",
       "      <td>[bingay, cool, handy, tonight, made, summercit...</td>\n",
       "      <td>[cool, tonight, made, work, lunch, bay, beauti...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>male</td>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>[[the, cynical, manipulation, of, voters, desi...</td>\n",
       "      <td>[the, cynical, manipulation, of, voters, desir...</td>\n",
       "      <td>[cynical, manipulation, voters, desire, honest...</td>\n",
       "      <td>[voters, honest, government, politics, climate...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>male</td>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>[[cannot, convert, to, object, on, sony, braav...</td>\n",
       "      <td>[cannot, convert, to, object, on, sony, braavi...</td>\n",
       "      <td>[cannot, convert, object, sony, braavia, happe...</td>\n",
       "      <td>[cannot, happening, week, idea, behind, every,...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>male</td>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>[[cat, is, kneading, maniac, floppycats], [the...</td>\n",
       "      <td>[cat, is, kneading, maniac, floppycats, the, l...</td>\n",
       "      <td>[cat, kneading, maniac, floppycats, left, goes...</td>\n",
       "      <td>[cat, left, goes, trump, giving, free, ride, p...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  gender                           user_id  \\\n",
       "0  d6b08022cdf758ead05e1c266649c393    male  d6b08022cdf758ead05e1c266649c393   \n",
       "1  9a989cb04766d5a89a65e8912d448328  female  9a989cb04766d5a89a65e8912d448328   \n",
       "2  2a1053a059d58fbafd3e782a8f7972c0    male  2a1053a059d58fbafd3e782a8f7972c0   \n",
       "3  6032537900368aca3d1546bd71ecabd1    male  6032537900368aca3d1546bd71ecabd1   \n",
       "4  d191280655be8108ec9928398ff5b563    male  d191280655be8108ec9928398ff5b563   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  [[what, odds, he, stops, whining, and, goes, o...   \n",
       "1  [[bingay, won, cool, handy, tonight], [], [we,...   \n",
       "2  [[the, cynical, manipulation, of, voters, desi...   \n",
       "3  [[cannot, convert, to, object, on, sony, braav...   \n",
       "4  [[cat, is, kneading, maniac, floppycats], [the...   \n",
       "\n",
       "                                           tweet_bag  \\\n",
       "0  [what, odds, he, stops, whining, and, goes, ou...   \n",
       "1  [bingay, won, cool, handy, tonight, we, made, ...   \n",
       "2  [the, cynical, manipulation, of, voters, desir...   \n",
       "3  [cannot, convert, to, object, on, sony, braavi...   \n",
       "4  [cat, is, kneading, maniac, floppycats, the, l...   \n",
       "\n",
       "                                   sw_removed_tweets  \\\n",
       "0  [odds, stops, whining, goes, gets, proper, job...   \n",
       "1  [bingay, cool, handy, tonight, made, summercit...   \n",
       "2  [cynical, manipulation, voters, desire, honest...   \n",
       "3  [cannot, convert, object, sony, braavia, happe...   \n",
       "4  [cat, kneading, maniac, floppycats, left, goes...   \n",
       "\n",
       "                                      freq_rm_tweets prediction  \n",
       "0  [goes, gets, proper, job, rest, us, would, ima...       male  \n",
       "1  [cool, tonight, made, work, lunch, bay, beauti...     female  \n",
       "2  [voters, honest, government, politics, climate...       male  \n",
       "3  [cannot, happening, week, idea, behind, every,...       male  \n",
       "4  [cat, left, goes, trump, giving, free, ride, p...       male  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting data to creating predict_label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = test_df[['id','prediction']] # extracting id and predicted to save data \n",
    "kaggle_df = test_df[['id','prediction']] # extracting id and predicted gender for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  gender\n",
       "0  d6b08022cdf758ead05e1c266649c393    male\n",
       "1  9a989cb04766d5a89a65e8912d448328  female\n",
       "2  2a1053a059d58fbafd3e782a8f7972c0    male\n",
       "3  6032537900368aca3d1546bd71ecabd1    male\n",
       "4  d191280655be8108ec9928398ff5b563    male"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns = ['id','gender']\n",
    "kaggle_df.columns = ['id','gender']\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('predict_label.csv',index=False) #saving result in predict_labels.csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting data to kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle_df = kaggle_df[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  gender\n",
       "0  d6b08022cdf758ead05e1c266649c393    male\n",
       "1  9a989cb04766d5a89a65e8912d448328  female\n",
       "2  2a1053a059d58fbafd3e782a8f7972c0    male\n",
       "3  6032537900368aca3d1546bd71ecabd1    male\n",
       "4  d191280655be8108ec9928398ff5b563    male"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kaggle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle_df['gender'] = kaggle_df['gender'].replace('female',0 ) # as specified converting female as o and male as 1 \n",
    "# kaggle_df['gender'] = kaggle_df['gender'].replace('male',1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  gender\n",
       "0  d6b08022cdf758ead05e1c266649c393       1\n",
       "1  9a989cb04766d5a89a65e8912d448328       0\n",
       "2  2a1053a059d58fbafd3e782a8f7972c0       1\n",
       "3  6032537900368aca3d1546bd71ecabd1       1\n",
       "4  d191280655be8108ec9928398ff5b563       1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kaggle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle_df.to_csv('predict_label_kaggle.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
